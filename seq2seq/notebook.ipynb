{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YlRH3mQM9tf"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIEGXF8oM9tt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e6abe3-7851-4e78-cf8f-2b4145ecb2fd"
      },
      "source": [
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twIcAJnyRkW-"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"rus.txt\", sep='\\t', header=None).drop(2, axis=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "yHzvuB34COlN",
        "outputId": "cfb051ff-a17e-47ee-f0ef-aecc3b8c42c3"
      },
      "source": [
        "df[0] = df[0].apply(lambda x: re.sub(r'[^a-z ]+', '', x.lower()))\n",
        "df[1] = df[1].apply(lambda x: re.sub(r'[^а-яё ]+', '', x.lower()))\n",
        "df.sample(10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48613</th>\n",
              "      <td>would tom do that</td>\n",
              "      <td>том бы стал это делать</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386402</th>\n",
              "      <td>its difficult to grow anything in this soil</td>\n",
              "      <td>на этой почве трудно чтото вырастить</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348196</th>\n",
              "      <td>i knew that tom did that intentionally</td>\n",
              "      <td>я знал что том нарочно это делает</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79744</th>\n",
              "      <td>go and see who it is</td>\n",
              "      <td>пойдите посмотрите кто это</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272549</th>\n",
              "      <td>tom eats nothing but white meat</td>\n",
              "      <td>том ничего не ест кроме белого мяса</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82912</th>\n",
              "      <td>i think youre drunk</td>\n",
              "      <td>помоему ты пьяная</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312331</th>\n",
              "      <td>tom dropped his phone in the water</td>\n",
              "      <td>том уронил телефон в воду</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179731</th>\n",
              "      <td>i dont even remember that</td>\n",
              "      <td>я этого даже не помню</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188799</th>\n",
              "      <td>tom is wearing black shoes</td>\n",
              "      <td>том в чёрных ботинках</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211410</th>\n",
              "      <td>youre divorced arent you</td>\n",
              "      <td>ты ведь разведён</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  0                                     1\n",
              "48613                             would tom do that                том бы стал это делать\n",
              "386402  its difficult to grow anything in this soil  на этой почве трудно чтото вырастить\n",
              "348196       i knew that tom did that intentionally     я знал что том нарочно это делает\n",
              "79744                          go and see who it is            пойдите посмотрите кто это\n",
              "272549              tom eats nothing but white meat   том ничего не ест кроме белого мяса\n",
              "82912                           i think youre drunk                     помоему ты пьяная\n",
              "312331           tom dropped his phone in the water             том уронил телефон в воду\n",
              "179731                    i dont even remember that                 я этого даже не помню\n",
              "188799                   tom is wearing black shoes                 том в чёрных ботинках\n",
              "211410                     youre divorced arent you                      ты ведь разведён"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwV3n87nDqLf",
        "outputId": "0b06d531-3d16-4e56-f266-507eeea29c70"
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s\",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[0].startswith(eng_prefixes)\n",
        "\n",
        "pairs = [p for p in zip(df[0].tolist(), df[1].tolist()) if filterPair(p)]\n",
        "print(len(pairs), random.choice(pairs))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4650 ('he is very kind to me', 'он очень ко мне добр')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyNnJyruM9t1"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dZOGjd5M9uE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61c4032-b7ae-4933-c386-f33786254fc3"
      },
      "source": [
        "def prepareData(lang1, lang2, pairs, reverse=False):\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'rus', pairs)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counted words:\n",
            "eng 2190\n",
            "rus 4163\n",
            "('she shut the door', 'она закрыла дверь')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgtWqznCM9uH"
      },
      "source": [
        "The Encoder\n",
        "-----------\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9vm9QBWM9uI"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, rnn_type, input_size, hidden_size, num_layers=1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.rnn = rnn_type(hidden_size, hidden_size, num_layers=num_layers)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input)\n",
        "        embedded = embedded.view(1, 1, -1)\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        if isinstance(self.rnn, nn.LSTM):\n",
        "            return (torch.zeros(self.num_layers, 1, self.hidden_size, device=device),\n",
        "                    torch.zeros(self.num_layers, 1, self.hidden_size, device=device))\n",
        "        return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwLTlgSyM9uK"
      },
      "source": [
        "The Decoder\n",
        "-----------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFbuUL1LM9uL"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, rnn_type, hidden_size, output_size, num_layers=1):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.rnn = rnn_type(hidden_size, hidden_size, num_layers=num_layers)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        if isinstance(self.rnn, nn.LSTM):\n",
        "            return (torch.zeros(1, 1, self.hidden_size, device=device),\n",
        "                    torch.zeros(1, 1, self.hidden_size, device=device))\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6gGPtXFM9uQ"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Fn8VDv8M9uS"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKsdwPmSM9uU"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_z_k5IiM9uX"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JXG-RzCM9uZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bxf45h6M9ud"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qUmQIGwM9uf"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi69a2NThnaH"
      },
      "source": [
        "# GRU с одним рекуррентным слоем\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_56t10oM9uh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d38b1dab-59f7-43c4-bab9-39ea7ed2519a"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(nn.GRU, input_lang.n_words, hidden_size).to(device)\n",
        "decoder1 = DecoderRNN(nn.GRU, hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "trainIters(encoder1, decoder1, 75000, print_every=5000)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 41s (- 9m 42s) (5000 6%) 4.1467\n",
            "1m 20s (- 8m 44s) (10000 13%) 3.6465\n",
            "2m 0s (- 8m 0s) (15000 20%) 3.0068\n",
            "2m 40s (- 7m 21s) (20000 26%) 2.4851\n",
            "3m 21s (- 6m 42s) (25000 33%) 2.0751\n",
            "4m 2s (- 6m 3s) (30000 40%) 1.6416\n",
            "4m 43s (- 5m 24s) (35000 46%) 1.3666\n",
            "5m 26s (- 4m 45s) (40000 53%) 1.1402\n",
            "6m 7s (- 4m 4s) (45000 60%) 0.9248\n",
            "6m 49s (- 3m 24s) (50000 66%) 0.7586\n",
            "7m 30s (- 2m 43s) (55000 73%) 0.6333\n",
            "8m 11s (- 2m 2s) (60000 80%) 0.5680\n",
            "8m 53s (- 1m 22s) (65000 86%) 0.5042\n",
            "9m 35s (- 0m 41s) (70000 93%) 0.4733\n",
            "10m 17s (- 0m 0s) (75000 100%) 0.4309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEoEylSyM9uj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105ced0e-72df-466e-ec59-d8298ae01f40"
      },
      "source": [
        "evaluateRandomly(encoder1, decoder1)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> he is one of my neighbours\n",
            "= он один из моих соседей\n",
            "< он один из моих соседей <EOS>\n",
            "\n",
            "> she is washing the car\n",
            "= она моет машину\n",
            "< она моет машину <EOS>\n",
            "\n",
            "> i am the same age\n",
            "= я того же возраста\n",
            "< мне столько же лет <EOS>\n",
            "\n",
            "> i am sick\n",
            "= мне дурно\n",
            "< я болен <EOS>\n",
            "\n",
            "> they are on good terms with their neighbors\n",
            "= у них хорошие отношения с соседями\n",
            "< они в хороших отношениях с соседями <EOS>\n",
            "\n",
            "> i am grateful to them\n",
            "= я благодарен им\n",
            "< я им признателен <EOS>\n",
            "\n",
            "> they are not coming today\n",
            "= они сегодня не придут\n",
            "< они сегодня не придут <EOS>\n",
            "\n",
            "> we are worried about you\n",
            "= мы за тебя беспокоимся\n",
            "< мы за вас беспокоимся <EOS>\n",
            "\n",
            "> she is eager to live in australia\n",
            "= она стремится жить в австралии\n",
            "< она стремится жить в австралии <EOS>\n",
            "\n",
            "> you are always as busy as a bee\n",
            "= ты всегда трудишься как пчела\n",
            "< ты всегда трудишься как пчела <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF8QSU1YiHWN"
      },
      "source": [
        "# GRU с двумя рекуррентными слоями"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK-ZLxUXNMXC",
        "outputId": "20825ffd-9212-4152-b4c3-2c5119864157"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder2 = EncoderRNN(nn.GRU, input_lang.n_words, hidden_size, 2).to(device)\n",
        "decoder2 = DecoderRNN(nn.GRU, hidden_size, output_lang.n_words, 2).to(device)\n",
        "\n",
        "trainIters(encoder2, decoder2, 75000, print_every=5000)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 51s (- 12m 4s) (5000 6%) 4.1548\n",
            "1m 41s (- 10m 56s) (10000 13%) 3.8152\n",
            "2m 31s (- 10m 6s) (15000 20%) 3.2783\n",
            "3m 22s (- 9m 16s) (20000 26%) 2.7649\n",
            "4m 13s (- 8m 27s) (25000 33%) 2.3014\n",
            "5m 4s (- 7m 37s) (30000 40%) 1.9008\n",
            "5m 57s (- 6m 48s) (35000 46%) 1.5721\n",
            "6m 49s (- 5m 58s) (40000 53%) 1.2825\n",
            "7m 41s (- 5m 7s) (45000 60%) 1.0686\n",
            "8m 34s (- 4m 17s) (50000 66%) 0.8893\n",
            "9m 26s (- 3m 26s) (55000 73%) 0.7429\n",
            "10m 18s (- 2m 34s) (60000 80%) 0.6584\n",
            "11m 11s (- 1m 43s) (65000 86%) 0.5767\n",
            "12m 3s (- 0m 51s) (70000 93%) 0.5253\n",
            "12m 56s (- 0m 0s) (75000 100%) 0.4645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcvDe5a7YeJg",
        "outputId": "87a508e6-5be8-4b97-95de-ede9e0faf9ca"
      },
      "source": [
        "evaluateRandomly(encoder2, decoder2)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> i am familiar with this neighborhood\n",
            "= мне знаком этот район\n",
            "< мне знаком этот район <EOS>\n",
            "\n",
            "> she is kissing him\n",
            "= она его целует\n",
            "< она целует его <EOS>\n",
            "\n",
            "> she is a secondrate singer at best\n",
            "= она в лучшем случае второсортная певичка\n",
            "< она в лучшем случае второсортная певица <EOS>\n",
            "\n",
            "> she is appearing on tv tonight\n",
            "= вечером её будут показывать по телевизору\n",
            "< вечером её будут показывать по телевизору <EOS>\n",
            "\n",
            "> you are going to have to pay for it\n",
            "= вам придётся за него заплатить\n",
            "< тебе придётся за неё заплатить <EOS>\n",
            "\n",
            "> he is about forty\n",
            "= ему лет сорок\n",
            "< ему около сорока <EOS>\n",
            "\n",
            "> she still loved him\n",
            "= она всё ещё любила его\n",
            "< она всё ещё любила его <EOS>\n",
            "\n",
            "> you arent canadian\n",
            "= ты не канадка\n",
            "< вы не канадка <EOS>\n",
            "\n",
            "> i am not leaving you\n",
            "= я вас не покидаю\n",
            "< я вас не покидаю <EOS>\n",
            "\n",
            "> i am eating an apple\n",
            "= я ем яблоко\n",
            "< я ем яблоко <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6HpT_BuiRC4"
      },
      "source": [
        "# LSTM с одним рекуррентным слоем"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-e-QNqpiOEm",
        "outputId": "059fd082-3dd9-4c8c-ee9d-bcdabfc471d5"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder3 = EncoderRNN(nn.LSTM, input_lang.n_words, hidden_size).to(device)\n",
        "decoder3 = DecoderRNN(nn.LSTM, hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "trainIters(encoder3, decoder3, 75000, print_every=5000)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 42s (- 9m 53s) (5000 6%) 4.3116\n",
            "1m 22s (- 8m 54s) (10000 13%) 3.9452\n",
            "2m 2s (- 8m 10s) (15000 20%) 3.3706\n",
            "2m 43s (- 7m 29s) (20000 26%) 2.8550\n",
            "3m 25s (- 6m 50s) (25000 33%) 2.3989\n",
            "4m 7s (- 6m 10s) (30000 40%) 1.9761\n",
            "4m 49s (- 5m 30s) (35000 46%) 1.6374\n",
            "5m 31s (- 4m 49s) (40000 53%) 1.3771\n",
            "6m 13s (- 4m 8s) (45000 60%) 1.1575\n",
            "6m 54s (- 3m 27s) (50000 66%) 0.9662\n",
            "7m 36s (- 2m 46s) (55000 73%) 0.8082\n",
            "8m 18s (- 2m 4s) (60000 80%) 0.7095\n",
            "9m 1s (- 1m 23s) (65000 86%) 0.6109\n",
            "9m 43s (- 0m 41s) (70000 93%) 0.5577\n",
            "10m 25s (- 0m 0s) (75000 100%) 0.4969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9axAW_Hid17",
        "outputId": "cf234724-5513-4fc4-bd43-6a99199efc90"
      },
      "source": [
        "evaluateRandomly(encoder3, decoder3)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> he isnt here because hes ill\n",
            "= его нет потому что он болеет\n",
            "< его нет нет потому что он <EOS>\n",
            "\n",
            "> she is a secondrate singer at best\n",
            "= она в лучшем случае второсортная певичка\n",
            "< она в лучшем случае второсортная певица <EOS>\n",
            "\n",
            "> he is quite a gentleman\n",
            "= он действительно джентльмен\n",
            "< он действительно джентльмен <EOS>\n",
            "\n",
            "> he is pleased with his new car\n",
            "= он доволен своим новым автомобилем\n",
            "< он доволен своей новой машиной <EOS>\n",
            "\n",
            "> she is younger than me\n",
            "= она младше меня\n",
            "< она младше меня <EOS>\n",
            "\n",
            "> i am wasting my time\n",
            "= я зря трачу время\n",
            "< я зря трачу время <EOS>\n",
            "\n",
            "> he is in the bathroom\n",
            "= он в ванной\n",
            "< он в ванной <EOS>\n",
            "\n",
            "> i am a tennis player\n",
            "= я теннисистка\n",
            "< я теннисистка <EOS>\n",
            "\n",
            "> they are in class\n",
            "= они в классе\n",
            "< они в классе <EOS>\n",
            "\n",
            "> he is not a doctor but a teacher\n",
            "= он не врач он учитель\n",
            "< он не доктор а доктор <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIeTBBWNiKHi"
      },
      "source": [
        "# LSTM с двумя рекуррентными слоями"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj_YCmNDbSAh",
        "outputId": "c04e64ca-c8b3-4bf6-faf5-93399762fb40"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder3 = EncoderRNN(nn.LSTM, input_lang.n_words, hidden_size, 2).to(device)\n",
        "decoder3 = DecoderRNN(nn.LSTM, hidden_size, output_lang.n_words, 2).to(device)\n",
        "\n",
        "trainIters(encoder3, decoder3, 75000, print_every=5000)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 52s (- 12m 20s) (5000 6%) 4.3639\n",
            "1m 43s (- 11m 14s) (10000 13%) 4.1525\n",
            "2m 35s (- 10m 23s) (15000 20%) 3.9034\n",
            "3m 28s (- 9m 32s) (20000 26%) 3.5555\n",
            "4m 20s (- 8m 41s) (25000 33%) 3.1415\n",
            "5m 14s (- 7m 51s) (30000 40%) 2.7507\n",
            "6m 7s (- 6m 59s) (35000 46%) 2.3641\n",
            "7m 0s (- 6m 8s) (40000 53%) 1.9821\n",
            "7m 55s (- 5m 16s) (45000 60%) 1.7031\n",
            "8m 48s (- 4m 24s) (50000 66%) 1.4201\n",
            "9m 42s (- 3m 31s) (55000 73%) 1.2199\n",
            "10m 37s (- 2m 39s) (60000 80%) 1.0632\n",
            "11m 31s (- 1m 46s) (65000 86%) 0.8923\n",
            "12m 25s (- 0m 53s) (70000 93%) 0.7687\n",
            "13m 19s (- 0m 0s) (75000 100%) 0.6553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqm-vH7pfIAN",
        "outputId": "3b77564d-b02e-44fa-d975-c84c82369b1b"
      },
      "source": [
        "evaluateRandomly(encoder3, decoder3)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> you arent in a hurry are you\n",
            "= ты же не торопишься\n",
            "< вы же не торопишься <EOS>\n",
            "\n",
            "> he is employed on the farm\n",
            "= он нанялся на ферму\n",
            "< его наняли на ферму <EOS>\n",
            "\n",
            "> he is an unsung hero\n",
            "= он  невоспетый герой\n",
            "< он  невоспетый герой <EOS>\n",
            "\n",
            "> we are all eager to know the truth\n",
            "= мы все жаждем знать правду\n",
            "< мы все жаждем знать правду <EOS>\n",
            "\n",
            "> we arent going to sing that song\n",
            "= мы не будем петь эту песню\n",
            "< мы не будем петь эту песню <EOS>\n",
            "\n",
            "> you are always watching tv\n",
            "= ты всё время смотришь телевизор\n",
            "< вы всё время смотрите телевизор <EOS>\n",
            "\n",
            "> he is capable of doing it\n",
            "= он способен сделать это\n",
            "< он способен сделать это <EOS>\n",
            "\n",
            "> i am downloading books\n",
            "= я скачиваю книги\n",
            "< я скачиваю книги <EOS>\n",
            "\n",
            "> he is a biologist\n",
            "= он биолог\n",
            "< он биолог <EOS>\n",
            "\n",
            "> i am counting on you\n",
            "= я на вас рассчитываю\n",
            "< я на вас рассчитываю <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}