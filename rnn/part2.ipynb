{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Лекция 6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:11:51.143288Z",
          "start_time": "2020-03-12T15:11:49.649354Z"
        },
        "id": "CCTjjOkk0pqX"
      },
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLCMAeLu0pqf"
      },
      "source": [
        "## Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:12:00.685533Z",
          "start_time": "2020-03-12T15:12:00.591616Z"
        },
        "id": "3HdabKpv0pqh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "446e3231-02b6-4ba8-ea8d-597487934cb7"
      },
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>episode_id</th>\n",
              "      <th>number</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>timestamp_in_ms</th>\n",
              "      <th>speaking_line</th>\n",
              "      <th>character_id</th>\n",
              "      <th>location_id</th>\n",
              "      <th>raw_character_text</th>\n",
              "      <th>raw_location_text</th>\n",
              "      <th>spoken_words</th>\n",
              "      <th>normalized_text</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>10368</td>\n",
              "      <td>35</td>\n",
              "      <td>29</td>\n",
              "      <td>Lisa Simpson: Maggie, look. What's that?</td>\n",
              "      <td>235000</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Simpson Home</td>\n",
              "      <td>Maggie, look. What's that?</td>\n",
              "      <td>maggie look whats that</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10369</td>\n",
              "      <td>35</td>\n",
              "      <td>30</td>\n",
              "      <td>Lisa Simpson: Lee-mur. Lee-mur.</td>\n",
              "      <td>237000</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Simpson Home</td>\n",
              "      <td>Lee-mur. Lee-mur.</td>\n",
              "      <td>lee-mur lee-mur</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>10370</td>\n",
              "      <td>35</td>\n",
              "      <td>31</td>\n",
              "      <td>Lisa Simpson: Zee-boo. Zee-boo.</td>\n",
              "      <td>239000</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Simpson Home</td>\n",
              "      <td>Zee-boo. Zee-boo.</td>\n",
              "      <td>zee-boo zee-boo</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>10372</td>\n",
              "      <td>35</td>\n",
              "      <td>33</td>\n",
              "      <td>Lisa Simpson: I'm trying to teach Maggie that ...</td>\n",
              "      <td>245000</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Simpson Home</td>\n",
              "      <td>I'm trying to teach Maggie that nature doesn't...</td>\n",
              "      <td>im trying to teach maggie that nature doesnt e...</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>10374</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>Lisa Simpson: It's like an ox, only it has a h...</td>\n",
              "      <td>254000</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Simpson Home</td>\n",
              "      <td>It's like an ox, only it has a hump and a dewl...</td>\n",
              "      <td>its like an ox only it has a hump and a dewlap...</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...  word_count\n",
              "0           0  ...         4.0\n",
              "1           1  ...         2.0\n",
              "2           2  ...         2.0\n",
              "3           3  ...        24.0\n",
              "4           4  ...        18.0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:12:15.820742Z",
          "start_time": "2020-03-12T15:12:15.809523Z"
        },
        "id": "MMR6pDix0pqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9f8aa0-2572-437b-9318-20be0cbcd98c"
      },
      "source": [
        "phrases = df['normalized_text'].tolist()\n",
        "phrases[:10]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['maggie look whats that',\n",
              " 'lee-mur lee-mur',\n",
              " 'zee-boo zee-boo',\n",
              " 'im trying to teach maggie that nature doesnt end with the barnyard i want her to have all the advantages that i didnt have',\n",
              " 'its like an ox only it has a hump and a dewlap hump and dew-lap hump and dew-lap',\n",
              " 'you know his blood type how romantic',\n",
              " 'oh yeah whats my shoe size',\n",
              " 'ring',\n",
              " 'yes dad',\n",
              " 'ooh look maggie what is that do-dec-ah-edron dodecahedron']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:12:32.809563Z",
          "start_time": "2020-03-12T15:12:32.768140Z"
        },
        "id": "GYBlUml90pqj"
      },
      "source": [
        "text = [[c for c in ph] for ph in phrases if type(ph) is str]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBWUtM480pqk"
      },
      "source": [
        "## Делаем массив с данными"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:12:53.641351Z",
          "start_time": "2020-03-12T15:12:53.636757Z"
        },
        "id": "CJA9260s0pqk"
      },
      "source": [
        "CHARS = set('abcdefghijklmnopqrstuvwxyz ')\n",
        "INDEX_TO_CHAR = ['none'] + [w for w in CHARS]\n",
        "CHAR_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_CHAR)}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:13:58.918002Z",
          "start_time": "2020-03-12T15:13:55.602551Z"
        },
        "id": "8lDiggz20pql"
      },
      "source": [
        "MAX_LEN = 50\n",
        "X = torch.zeros((len(text), MAX_LEN), dtype=int)\n",
        "for i in range(len(text)):\n",
        "    for j, w in enumerate(text[i]):\n",
        "        if j >= MAX_LEN:\n",
        "            break\n",
        "        X[i, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:14:24.776980Z",
          "start_time": "2020-03-12T15:14:24.761649Z"
        },
        "scrolled": true,
        "id": "a6sNBrw20pql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daef239e-b82d-4061-a198-d29571b14ac9"
      },
      "source": [
        "X[0:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[18,  9, 27, 27,  8, 15, 10,  7, 22, 22, 13, 10, 12, 26,  9, 16,  1, 10,\n",
              "         16, 26,  9, 16,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 7, 15, 15,  0, 18, 23,  6, 10,  7, 15, 15,  0, 18, 23,  6,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 3, 15, 15,  0, 17, 22, 22, 10,  3, 15, 15,  0, 17, 22, 22,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 8, 18, 10, 16,  6,  2,  8, 19, 27, 10, 16, 22, 10, 16, 15,  9,  5, 26,\n",
              "         10, 18,  9, 27, 27,  8, 15, 10, 16, 26,  9, 16, 10, 19,  9, 16, 23,  6,\n",
              "         15, 10, 25, 22, 15,  1, 19, 16, 10, 15, 19, 25, 10, 12],\n",
              "        [ 8, 16,  1, 10,  7,  8, 13, 15, 10,  9, 19, 10, 22, 20, 10, 22, 19,  7,\n",
              "          2, 10,  8, 16, 10, 26,  9,  1, 10,  9, 10, 26, 23, 18,  4, 10,  9, 19,\n",
              "         25, 10,  9, 10, 25, 15, 12,  7,  9,  4, 10, 26, 23, 18],\n",
              "        [ 2, 22, 23, 10, 13, 19, 22, 12, 10, 26,  8,  1, 10, 17,  7, 22, 22, 25,\n",
              "         10, 16,  2,  4, 15, 10, 26, 22, 12, 10,  6, 22, 18,  9, 19, 16,  8,  5,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [22, 26, 10,  2, 15,  9, 26, 10, 12, 26,  9, 16,  1, 10, 18,  2, 10,  1,\n",
              "         26, 22, 15, 10,  1,  8,  3, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 6,  8, 19, 27,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 2, 15,  1, 10, 25,  9, 25,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [22, 22, 26, 10,  7, 22, 22, 13, 10, 18,  9, 27, 27,  8, 15, 10, 12, 26,\n",
              "          9, 16, 10,  8,  1, 10, 16, 26,  9, 16, 10, 25, 22,  0, 25, 15,  5,  0,\n",
              "          9, 26,  0, 15, 25,  6, 22, 19, 10, 25, 22, 25, 15,  5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boNj9gN50pqm"
      },
      "source": [
        "## Смотрим на Embedding и RNN ячейку"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:14:15.694973Z",
          "start_time": "2020-03-12T15:14:15.644024Z"
        },
        "id": "gidDd8LR0pqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8bbc02f-8b8c-4ccf-eaf8-b5bcaef0136b"
      },
      "source": [
        "embeddings = torch.nn.Embedding(len(INDEX_TO_CHAR), 28)\n",
        "t = embeddings(X[0:10])\n",
        "t"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.9004,  0.0259,  0.4117,  ...,  0.6157, -1.0859, -2.1504],\n",
              "         [-0.9102,  1.0716,  1.6357,  ..., -0.2527, -0.7056, -1.3963],\n",
              "         [-0.1736, -0.3153, -2.1766,  ..., -0.0573,  1.9306, -0.6378],\n",
              "         ...,\n",
              "         [ 0.3864, -1.1453,  1.5496,  ...,  0.0854, -0.2570, -0.7662],\n",
              "         [ 0.3864, -1.1453,  1.5496,  ...,  0.0854, -0.2570, -0.7662],\n",
              "         [ 0.3864, -1.1453,  1.5496,  ...,  0.0854, -0.2570, -0.7662]],\n",
              "\n",
              "        [[-1.4930, -1.8454,  0.8021,  ...,  0.9483, -0.2257,  1.3879],\n",
              "         [ 0.1923,  1.1125, -1.9005,  ..., -0.0716, -0.0777, -1.6635],\n",
              "         [ 0.1923,  1.1125, -1.9005,  ..., -0.0716, -0.0777, -1.6635],\n",
              "         ...,\n",
              "         [ 0.3864, -1.1453,  1.5496,  ...,  0.0854, -0.2570, -0.7662],\n",
              "         [ 0.3864, -1.1453,  1.5496,  ...,  0.0854, -0.2570, -0.7662],\n",
              "         [ 0.3864, -1.1453,  1.5496,  ...,  0.0854, -0.2570, -0.7662]],\n",
              "\n",
              "        [[ 0.1963, -2.4907,  0.6245,  ...,  0.3238, -0.1116,  1.7483],\n",
              "         [ 0.1923,  1.1125, -1.9005,  ..., -0.0716, -0.0777, -1.6635],\n",
              "         [ 0.1923,  1.1125, -1.9005,  ..., -0.0716, -0.0777, -1.6635],\n",
              "         ...,\n",
              "         [ 0.3864, -1.1453,  1.5496,  ...,  0.0854, -0.2570, -0.7662],\n",
              "         [ 0.3864, -1.1453,  1.5496,  ...,  0.0854, -0.2570, -0.7662],\n",
              "         [ 0.3864, -1.1453,  1.5496,  ...,  0.0854, -0.2570, -0.7662]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.4580,  0.1014, -0.7533,  ...,  1.3777, -0.3658,  0.8342],\n",
              "         [ 0.0240, -0.6904, -0.6568,  ..., -0.1227, -1.0596, -0.5268],\n",
              "         [ 1.5068,  0.9571,  0.5312,  ...,  0.4589, -0.9607,  0.6259],\n",
              "         ...,\n",
              "         [ 0.3864, -1.1453,  1.5496,  ...,  0.0854, -0.2570, -0.7662],\n",
              "         [ 0.3864, -1.1453,  1.5496,  ...,  0.0854, -0.2570, -0.7662],\n",
              "         [ 0.3864, -1.1453,  1.5496,  ...,  0.0854, -0.2570, -0.7662]],\n",
              "\n",
              "        [[-0.5900,  0.5041,  0.6041,  ..., -0.1851, -0.9709,  1.4930],\n",
              "         [ 0.1923,  1.1125, -1.9005,  ..., -0.0716, -0.0777, -1.6635],\n",
              "         [-0.2528,  1.0640,  0.0693,  ..., -1.4015, -1.3890, -2.4225],\n",
              "         ...,\n",
              "         [ 0.3864, -1.1453,  1.5496,  ...,  0.0854, -0.2570, -0.7662],\n",
              "         [ 0.3864, -1.1453,  1.5496,  ...,  0.0854, -0.2570, -0.7662],\n",
              "         [ 0.3864, -1.1453,  1.5496,  ...,  0.0854, -0.2570, -0.7662]],\n",
              "\n",
              "        [[ 0.9642, -0.2367, -1.3684,  ...,  0.4463,  0.3632,  0.6090],\n",
              "         [ 0.9642, -0.2367, -1.3684,  ...,  0.4463,  0.3632,  0.6090],\n",
              "         [-0.3004,  0.1316,  1.0501,  ..., -1.4252, -0.8747,  0.7454],\n",
              "         ...,\n",
              "         [-0.7312, -0.0191, -0.3313,  ..., -0.0616,  0.4415, -0.3956],\n",
              "         [ 0.1923,  1.1125, -1.9005,  ..., -0.0716, -0.0777, -1.6635],\n",
              "         [ 0.4680,  0.7042, -1.0673,  ..., -0.6122, -0.2945, -0.4905]]],\n",
              "       grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:14:48.405046Z",
          "start_time": "2020-03-12T15:14:48.400041Z"
        },
        "id": "7E5MgCbm0pqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b2288d1-8d93-4bc5-ab75-14fc62822888"
      },
      "source": [
        "t.shape, X[0:10].shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10, 50, 28]), torch.Size([10, 50]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:18:23.190978Z",
          "start_time": "2020-03-12T15:18:23.180493Z"
        },
        "id": "BQSBzFDm0pqn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "816cde62-07e0-4408-fa55-ae483a256681"
      },
      "source": [
        "rnn = torch.nn.RNN(28, 128, batch_first=True)\n",
        "o, s = rnn(t)\n",
        "o.shape, s.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10, 50, 128]), torch.Size([1, 10, 128]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:18:35.190131Z",
          "start_time": "2020-03-12T15:18:35.180708Z"
        },
        "id": "8XqT9jxK0pqn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2abf3cc1-6e76-4a95-8df6-09a5511c87ee"
      },
      "source": [
        "o, s2 = rnn(t, s)\n",
        "o.shape, s2.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10, 50, 128]), torch.Size([1, 10, 128]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpYm3xg90pqo"
      },
      "source": [
        "## Практика. Реализуйте код модели нейронной сети\n",
        "3 слоя - embeding (28), скрытая ячейка (128), полносвязанный из состояния rnn в букву (28)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:26:45.716418Z",
          "start_time": "2020-03-12T15:26:45.710937Z"
        },
        "id": "nassLST90pqo"
      },
      "source": [
        "class Network(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super(Network, self).__init__()\n",
        "        self.embed = torch.nn.Embedding(vocab_size, embed_dim)\n",
        "        self.rnn = torch.nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.linear = torch.nn.Linear(hidden_dim, vocab_size)\n",
        "        \n",
        "    def forward(self, sentences, state=None):\n",
        "        embed = self.embed(sentences)\n",
        "        out, _ = self.rnn(embed)\n",
        "        return self.linear(out)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:20:53.260599Z",
          "start_time": "2020-03-12T15:20:53.256979Z"
        },
        "id": "JX8QTNUP0pqo"
      },
      "source": [
        "vocab_size = len(CHAR_TO_INDEX)\n",
        "embed_dim = 28\n",
        "hidden_dim = 128\n",
        "\n",
        "model = Network(vocab_size, embed_dim, hidden_dim)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:21:01.929404Z",
          "start_time": "2020-03-12T15:21:01.925999Z"
        },
        "id": "gxg1WmC40pqp"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=.05)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:22:04.410583Z",
          "start_time": "2020-03-12T15:21:34.734119Z"
        },
        "scrolled": true,
        "id": "Sebr13h-0pqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f94d51-688e-4754-dda9-e49af6c931aa"
      },
      "source": [
        "for ep in range(10):\n",
        "    start = time.time()\n",
        "    train_loss = 0.\n",
        "    train_passed = 0\n",
        "    rnn.train()\n",
        "    for i in range(int(len(X) / 100)):\n",
        "        batch = X[i * 100:(i + 1) * 100]\n",
        "        X_batch = batch[:, :-1]\n",
        "        Y_batch = batch[:, 1:].flatten()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        answers = model.forward(X_batch)\n",
        "        answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
        "        loss = criterion(answers, Y_batch)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_passed += 1\n",
        "\n",
        "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0. Time: 4.323, Train loss: 2.085\n",
            "Epoch 1. Time: 4.170, Train loss: 1.816\n",
            "Epoch 2. Time: 4.764, Train loss: 1.737\n",
            "Epoch 3. Time: 6.380, Train loss: 1.688\n",
            "Epoch 4. Time: 6.189, Train loss: 1.654\n",
            "Epoch 5. Time: 4.715, Train loss: 1.628\n",
            "Epoch 6. Time: 4.109, Train loss: 1.607\n",
            "Epoch 7. Time: 4.223, Train loss: 1.588\n",
            "Epoch 8. Time: 4.186, Train loss: 1.572\n",
            "Epoch 9. Time: 4.121, Train loss: 1.558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:28:40.363097Z",
          "start_time": "2020-03-12T15:28:40.357998Z"
        },
        "id": "JOasZSoC0pqq"
      },
      "source": [
        "## Практика. Реализуйте код генерации следующей буквы на основе модели\n",
        "Логика такая:\n",
        "    - Сначала кормим в нее буквы из sentence (прогревая состояние)\n",
        "    - Затем пока не получим none (0) берем самую вероятную букву и добавляем ее в sentence\n",
        "    - Повторяем"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:28:59.592247Z",
          "start_time": "2020-03-12T15:28:59.589338Z"
        },
        "id": "3vqJYTJH0pqq"
      },
      "source": [
        "def generate_sentence():\n",
        "    sentence = ['h', 'e', 'l', 'l', 'o']\n",
        "    X = torch.zeros((1, len(sentence)), dtype=int)\n",
        "    for j, w in enumerate(sentence):\n",
        "      if j >= MAX_LEN:\n",
        "        break\n",
        "      X[0, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])\n",
        "\n",
        "    for i in range(MAX_LEN):\n",
        "      o = model(X)\n",
        "      w = torch.argmax(o[-1, -1,:], keepdim=True)\n",
        "      X = torch.cat([X, w.unsqueeze(0).unsqueeze(0)], axis=1)\n",
        "      char = INDEX_TO_CHAR[w]\n",
        "      if char == \"none\":\n",
        "        break\n",
        "      sentence.append(char)\n",
        "    return \"\".join(sentence)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:22:28.324297Z",
          "start_time": "2020-03-12T15:22:28.291209Z"
        },
        "id": "aaCKbWUk0pqq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0a665995-4e97-4086-e5e8-61f06fea3583"
      },
      "source": [
        "generate_sentence()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hello the the the the the the the the the the the the t'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:23:13.963511Z",
          "start_time": "2020-03-12T15:22:45.311457Z"
        },
        "id": "iZSmRotg0pqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cbe17d1-4372-42c4-c699-2c5b6f88ec7b"
      },
      "source": [
        "for ep in range(50):\n",
        "    start = time.time()\n",
        "    train_loss = 0.\n",
        "    train_passed = 0\n",
        "\n",
        "    for i in range(int(len(X) / 100)):\n",
        "        batch = X[i * 100:(i + 1) * 100]\n",
        "        X_batch = batch[:, :-1]\n",
        "        Y_batch = batch[:, 1:].flatten()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        answers = model.forward(X_batch)\n",
        "        answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
        "        loss = criterion(answers, Y_batch)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_passed += 1\n",
        "\n",
        "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))\n",
        "    print(generate_sentence())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0. Time: 4.247, Train loss: 1.228\n",
            "hellore it the some on the some on the some on the some\n",
            "Epoch 1. Time: 4.182, Train loss: 1.226\n",
            "hello it the some on the some on the some on the some o\n",
            "Epoch 2. Time: 4.171, Train loss: 1.225\n",
            "hello it the some on the some on the some on the some o\n",
            "Epoch 3. Time: 4.205, Train loss: 1.223\n",
            "hello it the some on the some on the some on the some o\n",
            "Epoch 4. Time: 4.157, Train loss: 1.221\n",
            "hello it the some on the some on the some on the some o\n",
            "Epoch 5. Time: 4.158, Train loss: 1.219\n",
            "hello it the some on the some on the some on the some o\n",
            "Epoch 6. Time: 4.135, Train loss: 1.218\n",
            "hello it the some on the some on the some on the some o\n",
            "Epoch 7. Time: 4.147, Train loss: 1.216\n",
            "hello it the some on the some on the some on the some o\n",
            "Epoch 8. Time: 4.138, Train loss: 1.214\n",
            "hello it the some on the some on the some on the some o\n",
            "Epoch 9. Time: 4.159, Train loss: 1.213\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 10. Time: 4.255, Train loss: 1.211\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 11. Time: 4.148, Train loss: 1.209\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 12. Time: 4.135, Train loss: 1.208\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 13. Time: 4.148, Train loss: 1.206\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 14. Time: 4.183, Train loss: 1.205\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 15. Time: 4.212, Train loss: 1.203\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 16. Time: 4.172, Train loss: 1.202\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 17. Time: 4.167, Train loss: 1.200\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 18. Time: 4.177, Train loss: 1.199\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 19. Time: 4.284, Train loss: 1.197\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 20. Time: 4.194, Train loss: 1.196\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 21. Time: 4.214, Train loss: 1.194\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 22. Time: 4.172, Train loss: 1.193\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 23. Time: 4.182, Train loss: 1.192\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 24. Time: 4.204, Train loss: 1.190\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 25. Time: 4.167, Train loss: 1.189\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 26. Time: 4.271, Train loss: 1.188\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 27. Time: 4.278, Train loss: 1.186\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 28. Time: 4.204, Train loss: 1.185\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 29. Time: 4.164, Train loss: 1.184\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 30. Time: 4.169, Train loss: 1.182\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 31. Time: 4.255, Train loss: 1.181\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 32. Time: 4.169, Train loss: 1.180\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 33. Time: 4.250, Train loss: 1.179\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 34. Time: 4.257, Train loss: 1.177\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 35. Time: 4.314, Train loss: 1.176\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 36. Time: 4.219, Train loss: 1.175\n",
            "hello it the simplet it the simplet it the simplet it t\n",
            "Epoch 37. Time: 4.157, Train loss: 1.174\n",
            "hello it the simpson and the simpson and the simpson an\n",
            "Epoch 38. Time: 4.231, Train loss: 1.173\n",
            "hello it the simpson and the simpson and the simpson an\n",
            "Epoch 39. Time: 4.159, Train loss: 1.171\n",
            "hello it the simpson and the simpson and the simpson an\n",
            "Epoch 40. Time: 4.152, Train loss: 1.170\n",
            "hello it the simpson and the simpson and the simpson an\n",
            "Epoch 41. Time: 4.152, Train loss: 1.169\n",
            "hello it the simpson and the simpson and the simpson an\n",
            "Epoch 42. Time: 4.198, Train loss: 1.168\n",
            "hello it the simpson and the simpson and the simpson an\n",
            "Epoch 43. Time: 4.230, Train loss: 1.167\n",
            "hello it the simpson and the simpson and the simpson an\n",
            "Epoch 44. Time: 4.152, Train loss: 1.166\n",
            "hello it the simpson and the simpson and the simpson an\n",
            "Epoch 45. Time: 4.184, Train loss: 1.165\n",
            "hello it the simpson and the simpson and the simpson an\n",
            "Epoch 46. Time: 4.160, Train loss: 1.164\n",
            "hello it the simpson and the simpson and the simpson an\n",
            "Epoch 47. Time: 4.181, Train loss: 1.163\n",
            "hello it the simpson and the simpson and the simpson an\n",
            "Epoch 48. Time: 4.174, Train loss: 1.162\n",
            "hello it the simpson and the simpson and the simpson an\n",
            "Epoch 49. Time: 4.160, Train loss: 1.160\n",
            "hello it the simpson and the simpson and the simpson an\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Qs-22i0pqr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}