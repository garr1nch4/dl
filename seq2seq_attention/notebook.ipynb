{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YlRH3mQM9tf"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIEGXF8oM9tt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8104c195-529b-45a7-8310-7ca8260a1b3c"
      },
      "source": [
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twIcAJnyRkW-"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"rus.txt\", sep='\\t', header=None).drop(2, axis=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "yHzvuB34COlN",
        "outputId": "48a02770-7979-48ae-e6f8-c98d16a167a0"
      },
      "source": [
        "df[0] = df[0].apply(lambda x: re.sub(r'[^a-z ]+', '', x.lower()))\n",
        "df[1] = df[1].apply(lambda x: re.sub(r'[^а-яё ]+', '', x.lower()))\n",
        "df.sample(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24971</th>\n",
              "      <td>they wont come</td>\n",
              "      <td>они не придут</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299980</th>\n",
              "      <td>tom didnt know what he was doing</td>\n",
              "      <td>том не знал что делает</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194532</th>\n",
              "      <td>did you get your money back</td>\n",
              "      <td>ты вернул свои деньги</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297786</th>\n",
              "      <td>my french teacher was very strict</td>\n",
              "      <td>мой учитель французского был очень строгий</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22642</th>\n",
              "      <td>i won the event</td>\n",
              "      <td>я выиграл в этом мероприятии</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106487</th>\n",
              "      <td>what a touching story</td>\n",
              "      <td>какая трогательная история</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105502</th>\n",
              "      <td>tom was wearing jeans</td>\n",
              "      <td>том был в джинсах</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376807</th>\n",
              "      <td>it is getting colder and colder day by day</td>\n",
              "      <td>с каждым днём холодает</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73391</th>\n",
              "      <td>tom hid his weapons</td>\n",
              "      <td>том спрятал своё оружие</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344728</th>\n",
              "      <td>we have had a lot of rain this summer</td>\n",
              "      <td>этим летом у нас было много дождей</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 0                                           1\n",
              "24971                               they wont come                               они не придут\n",
              "299980            tom didnt know what he was doing                      том не знал что делает\n",
              "194532                 did you get your money back                       ты вернул свои деньги\n",
              "297786           my french teacher was very strict  мой учитель французского был очень строгий\n",
              "22642                              i won the event                я выиграл в этом мероприятии\n",
              "106487                       what a touching story                  какая трогательная история\n",
              "105502                       tom was wearing jeans                           том был в джинсах\n",
              "376807  it is getting colder and colder day by day                      с каждым днём холодает\n",
              "73391                          tom hid his weapons                     том спрятал своё оружие\n",
              "344728       we have had a lot of rain this summer          этим летом у нас было много дождей"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwV3n87nDqLf",
        "outputId": "81c24fb7-0351-4c43-c069-de02fc14298b"
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s\",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[0].startswith(eng_prefixes)\n",
        "\n",
        "pairs = [p for p in zip(df[0].tolist(), df[1].tolist()) if filterPair(p)]\n",
        "print(len(pairs), random.choice(pairs))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4650 ('he is still young', 'он ещё молодой')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyNnJyruM9t1"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dZOGjd5M9uE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb7c546-ed9f-4a3c-aefc-48a3551fcdd1"
      },
      "source": [
        "def prepareData(lang1, lang2, pairs, reverse=False):\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'rus', pairs)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counted words:\n",
            "eng 2190\n",
            "rus 4163\n",
            "('i am so sorry to have kept you waiting', 'мне так жаль что я заставила вас ждать')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgtWqznCM9uH"
      },
      "source": [
        "The Encoder\n",
        "-----------\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9vm9QBWM9uI"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6gGPtXFM9uQ"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Fn8VDv8M9uS"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKsdwPmSM9uU"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_z_k5IiM9uX"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JXG-RzCM9uZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bxf45h6M9ud"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qUmQIGwM9uf"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi69a2NThnaH"
      },
      "source": [
        "# DecoderScalar\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFbuUL1LM9uL"
      },
      "source": [
        "# class AttnDecoderRNN(nn.Module):\n",
        "#     def __init__(self, hidden_size, output_size, dropout_p=0.1,\n",
        "#                  max_length=MAX_LENGTH):\n",
        "#         super(AttnDecoderRNN, self).__init__()\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.output_size = output_size\n",
        "#         self.dropout_p = dropout_p\n",
        "#         self.max_length = max_length + 2\n",
        "\n",
        "#         self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "#         self.dropout = nn.Dropout(self.dropout_p)\n",
        "#         self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "#         self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "#         self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "#     def forward(self, input, hidden, encoder_outputs):\n",
        "#         embedded = self.embedding(input).view(1, 1, -1)\n",
        "#         embedded = self.dropout(embedded)\n",
        "\n",
        "#         weights = []\n",
        "#         for i in range(len(encoder_outputs)):\n",
        "#             weights.append(\n",
        "#                 torch.div(torch.matmul(hidden[0][0], encoder_outputs[i]),\n",
        "#                           torch.sqrt(\n",
        "#                               torch.tensor(self.max_length, dtype=torch.float,\n",
        "#                                            device=device))\n",
        "#                           )\n",
        "#                 )\n",
        "#         attn_weights = F.softmax(torch.tensor(weights, device=device))\n",
        "\n",
        "#         attn_applied = torch.bmm(attn_weights.unsqueeze(0).unsqueeze(0),\n",
        "#                                  encoder_outputs.view(1, -1, self.hidden_size)\n",
        "#                                  )\n",
        "\n",
        "#         output = torch.cat((attn_applied[0], embedded[0]), 1)\n",
        "#         output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "#         output = F.relu(output)\n",
        "#         output, hidden = self.gru(output, hidden)\n",
        "\n",
        "#         output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "#         return output, hidden, attn_weights\n",
        "\n",
        "#     def initHidden(self):\n",
        "#         return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "        weights = torch.div(\n",
        "            torch.matmul(encoder_outputs, hidden[0][0]),\n",
        "            torch.sqrt(torch.tensor(self.max_length, dtype=torch.float, device=device))\n",
        "        )\n",
        "        \n",
        "        attn_weights = F.softmax(weights)\n",
        "        attn_applied = torch.bmm(attn_weights.view(1, 1, -1), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_56t10oM9uh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c6ebfba-f3d2-4da6-e1bb-58b36e5b771f"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0m 58s (- 13m 32s) (5000 6%) 4.1367\n",
            "1m 55s (- 12m 28s) (10000 13%) 3.5649\n",
            "2m 53s (- 11m 32s) (15000 20%) 2.9518\n",
            "3m 51s (- 10m 35s) (20000 26%) 2.4082\n",
            "4m 49s (- 9m 39s) (25000 33%) 1.9368\n",
            "5m 48s (- 8m 42s) (30000 40%) 1.5792\n",
            "6m 47s (- 7m 45s) (35000 46%) 1.3195\n",
            "7m 46s (- 6m 47s) (40000 53%) 1.0611\n",
            "8m 45s (- 5m 50s) (45000 60%) 0.9149\n",
            "9m 45s (- 4m 52s) (50000 66%) 0.7642\n",
            "10m 44s (- 3m 54s) (55000 73%) 0.6736\n",
            "11m 43s (- 2m 55s) (60000 80%) 0.6037\n",
            "12m 43s (- 1m 57s) (65000 86%) 0.5245\n",
            "13m 42s (- 0m 58s) (70000 93%) 0.4769\n",
            "14m 42s (- 0m 0s) (75000 100%) 0.4651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEoEylSyM9uj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "943f0d87-e8ea-48cf-e094-c2181ad7be96"
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> you arent allowed to go into that room\n",
            "= тебе в эту комнату нельзя\n",
            "< вам в нельзя комнату нельзя <EOS>\n",
            "\n",
            "> you arent alone\n",
            "= вы не одни\n",
            "< ты не один <EOS>\n",
            "\n",
            "> she seldom if ever goes to movies by herself\n",
            "= она если и ходит одна в кино то редко\n",
            "< она редко если вообще одна на то редко <EOS>\n",
            "\n",
            "> you are in part responsible for it\n",
            "= частично за это ответственны вы\n",
            "< частично за это отвечаете вы <EOS>\n",
            "\n",
            "> i am too busy to go\n",
            "= я слишком занят чтобы идти\n",
            "< я слишком занят чтобы идти <EOS>\n",
            "\n",
            "> he is ready to work\n",
            "= он готов к работе\n",
            "< он готов к работе <EOS>\n",
            "\n",
            "> he is boiling with rage\n",
            "= в нём кипит ярость\n",
            "< в нём кипит ярость <EOS>\n",
            "\n",
            "> they are supposed to obey the orders\n",
            "= они обязаны подчиняться приказам\n",
            "< они обязаны подчиняться приказам <EOS>\n",
            "\n",
            "> he is a close friend of my brother\n",
            "= он близкий друг моего брата\n",
            "< он близкий друг моего брата <EOS>\n",
            "\n",
            "> they are taking a walk\n",
            "= они прогуливаются\n",
            "< они совершают пешую прогулку <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2tfcWgGStbG"
      },
      "source": [
        "# DecoderMLP\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1EAOiwhij93"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0n7Z56UjgVB",
        "outputId": "5fd7945b-0acb-4ed2-d067-8efdea218b02"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0m 59s (- 13m 54s) (5000 6%) 4.1034\n",
            "1m 57s (- 12m 43s) (10000 13%) 3.5429\n",
            "2m 55s (- 11m 43s) (15000 20%) 2.9226\n",
            "3m 55s (- 10m 47s) (20000 26%) 2.3744\n",
            "4m 54s (- 9m 49s) (25000 33%) 1.9125\n",
            "5m 54s (- 8m 51s) (30000 40%) 1.5583\n",
            "6m 54s (- 7m 53s) (35000 46%) 1.2843\n",
            "7m 53s (- 6m 54s) (40000 53%) 1.0651\n",
            "8m 53s (- 5m 55s) (45000 60%) 0.8865\n",
            "9m 53s (- 4m 56s) (50000 66%) 0.7709\n",
            "10m 53s (- 3m 57s) (55000 73%) 0.6567\n",
            "11m 52s (- 2m 58s) (60000 80%) 0.5772\n",
            "12m 52s (- 1m 58s) (65000 86%) 0.5130\n",
            "13m 53s (- 0m 59s) (70000 93%) 0.4866\n",
            "14m 53s (- 0m 0s) (75000 100%) 0.4426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYsB7Jk_px0a",
        "outputId": "e9017888-124c-43ce-de7c-d093e0e7385b"
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> i am too short\n",
            "= я слишком низкий\n",
            "< я слишком низкий <EOS>\n",
            "\n",
            "> i am glad that you have returned safe\n",
            "= я рад что ты вернулся целым и невредимым\n",
            "< я рад что вы вернулись целыми и невредимыми <EOS>\n",
            "\n",
            "> they are manufactured in various sizes\n",
            "= они произведены в различных размерах\n",
            "< они произведены в различных размерах <EOS>\n",
            "\n",
            "> he is a famous composer\n",
            "= он знаменитый композитор\n",
            "< он известный композитор <EOS>\n",
            "\n",
            "> he is respected by everyone\n",
            "= его все уважают\n",
            "< его все уважают <EOS>\n",
            "\n",
            "> i am allowed  yen a month for books\n",
            "= мне положено   иен в месяц на книги\n",
            "< мне положено   иен в месяц на книги <EOS>\n",
            "\n",
            "> i am a stranger here\n",
            "= я здесь человек новый\n",
            "< я здесь человек новый <EOS>\n",
            "\n",
            "> i am painting my garage\n",
            "= я крашу свой гараж\n",
            "< я крашу свой гараж <EOS>\n",
            "\n",
            "> he is at the office\n",
            "= он в офисе\n",
            "< он в офисе <EOS>\n",
            "\n",
            "> she is toms older sister\n",
            "= она старшая сестра тома\n",
            "< она старшая сестра тома <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}